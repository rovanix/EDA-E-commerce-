# -*- coding: utf-8 -*-
"""Explanatory Data Analysis (E-Commerce)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gd_cFtxj561Rh35n7_RNIjFLEWDAe0Jp

# **E-commerce Explanatory Data Analysis Project (EDA)**


Dataset: [Ecommerce Dataset for Data Analysis](https://www.kaggle.com/datasets/shrishtimanja/ecommerce-dataset-for-data-analysis?select=project1_df.csv)

## INTRODUCTION

The retail market in today's date is a competitive one. Due to this, deciphering the customer's purchase behavior is essential to sustain growth. A business that leverages data backed insights is placed better to optimize product offerings, run effective marketing campaigns and increase customer satisfaction levels.

The dataset used for this Explanatory Data Analysis(EDA) consists of detailed information on customer purchases which include:



1.   Purchase item details (Date, Product Category, Region, Payment Method).
2.  Customer Demographics (Age , Gender, City).
3. Financial Statistics (Gross Amount, Net Amount, Discount).

### Business Context

Our client is RovanMart Pvt Ltd., a small sized retail and e-commerce company operating in multiple cities in India. The business sells a range of products such as Clothing, Electronics, Beauty & Health and Household items. They operate both online and offline.

RovanMart has been collecting transaction data from its Sales Operations. The dataset contains:

1.   Purchase item details (Date, Product Category, Region, Payment Method).
2.  Customer Demographics (Age , Gender, City).
3. Financial Statistics (Gross Amount, Net Amount, Discount).
4. Payment Information (Cash on Delivery, Credit Card, Debit Card).

Although the company has high amounts of data, it lacks in-house expertise to analyze and find meaningful insights. The leadership team has framed a few Business Questions which needs to be answered.

### Business Questions

1. Which Product Category generates the highest revenue by
sale?
2. Which age group and gender contribute to most of the sales in total?
3. How do the sales vary in different regions?
4. Which of purchase methods (Debit Card, Cash On Delivery, etc) is most common among the customer?
5. What is the fluctuation of sales for top product categories by season and time of day?
6. What relationship do Discount_Percentage and Purchase_Frequency show?

### **Why Data Science is needed?**

They have engaged us as Data Scientists to perform Explanatory Data Analysis(EDA) on their dataset. By uncovering patterns, trends and anomalies we aim to give actionable insights to RovanMart.


1. To improve market targetting by focusing on the correct customer segments.
2. To optimize discount strategies to balance revenue and profitability.
3. To strengthen regional and product strategy on account of sales performance.
4. To establish a foundation for data driven decision making in the company.

### Importing the Python Libraries essential for Explanatory Data Analysis
* Pandas for data handling

* numpy for numerical calculations.

* matplotlib and seaborn for data visualization.
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

"""### Importing the Dataset for Analysis

"""

df = pd.read_csv('/content/project1_df.csv')

"""### Preview of the Dataset"""

df.shape

df.head(10)

df.dtypes

df.describe()

"""## **Data Cleaning**

### Checking for Null Values
"""

df.isnull().sum()

"""### Removing Null Values"""

df["Discount Name"] = df["Discount Name"].fillna("No Discount")
df.isnull().sum()

"""### To Check for Duplicates"""

df = df.drop_duplicates()
df.isnull().sum()

"""### Check for missing values"""

print("Missing values after cleaning:")
print(df.isnull().sum())
print("\nData types after cleaning:")
print(df.dtypes)

"""## Feature Engineering

Preparaing the Dataset for Feature Engineering.
"""

df['Purchase Date'] = pd.to_datetime(df['Purchase Date'], format='%d/%m/%Y %H:%M:%S', errors='coerce')
df["Discount Name"] = df["Discount Name"].fillna("No Discount")
df.dropna(subset=['Purchase Date'], inplace=True)
print("Data prepared. Shape:", df.shape)
df.head()

"""### Time Feature Engineering
Extraction of year, month, day of the week and hour.
"""

df['Purchase_Year'] = df['Purchase Date'].dt.year
df['Purchase_Month'] = df['Purchase Date'].dt.month_name()
df['Purchase_DayOfWeek'] = df['Purchase Date'].dt.day_name()
df['Purchase_Hour'] = df['Purchase Date'].dt.hour

print("Added Year, Month, Day of Week, and Hour features.")
df[['Purchase Date', 'Purchase_Year', 'Purchase_Month', 'Purchase_DayOfWeek', 'Purchase_Hour']].head()

"""Creating a "Time of Day" and "Season" feature."""

def get_time_of_day(hour):
    if 5 <= hour < 12:
        return 'Morning'
    elif 12 <= hour < 17:
        return 'Afternoon'
    elif 17 <= hour < 21:
        return 'Evening'
    else:
        return 'Night'

df['Purchase_TimeOfDay'] = df['Purchase_Hour'].apply(get_time_of_day)

# Create a "Season" feature based on the month
def get_season(month):
    if month in ['December', 'January', 'February']:
        return 'Winter'
    elif month in ['March', 'April', 'May']:
        return 'Spring'
    elif month in ['June', 'July', 'August']:
        return 'Summer'
    else:
        return 'Autumn'

df['Purchase_Season'] = df['Purchase_Month'].apply(get_season)

print("Added TimeOfDay and Season features.")
df[['Purchase_Month', 'Purchase_Season', 'Purchase_Hour', 'Purchase_TimeOfDay']].head()

"""### Financial Engineering
Calculation of Discount Percentage.
* This will help in standardization of the discount relative to the items price.

Formula used:

Discount Percentage = (Discount Amount /  Gross Amount) x 100
"""

df['Discount_Percentage'] = (df['Discount Amount (INR)'] / df['Gross Amount']) * 100
df['Discount_Percentage'].fillna(0, inplace=True)
df['Discount_Percentage'] = df['Discount_Percentage'].replace([np.inf, -np.inf], 0)


print("Added Discount_Percentage feature.")
df[['Gross Amount', 'Discount Amount (INR)', 'Discount_Percentage']].head(10)

"""### Customer Churn Engineering

A customer who has not made a purchase for a specific period (180 days in this case) will be defined as a churn customer, thus churn will be calculated based on recency.
"""

snapshot_date = df['Purchase Date'].max()
print(f"Snapshot date for churn analysis: {snapshot_date.date()}")
customer_last_purchase = df.groupby('CID')['Purchase Date'].max().reset_index()
customer_last_purchase.rename(columns={'Purchase Date': 'Last_Purchase_Date'}, inplace=True)
customer_last_purchase['Recency_Days'] = (snapshot_date - customer_last_purchase['Last_Purchase_Date']).dt.days

churn_threshold_days = 180
customer_last_purchase['Is_Churned'] = (customer_last_purchase['Recency_Days'] > churn_threshold_days).astype(int)

df = pd.merge(df, customer_last_purchase[['CID', 'Is_Churned', 'Recency_Days']], on='CID', how='left')
print(f"\nAdded 'Is_Churned' and 'Recency_Days' features based on a {churn_threshold_days}-day inactivity period.")
df[['CID', 'Purchase Date', 'Recency_Days', 'Is_Churned']].head()

"""## Data Exploration

### Categorical Data Frequencies
"""

print("\nValue Counts (Categorical Columns):\n")

print("Gender:\n", df["Gender"].value_counts(), "\n")
print("Age Group:\n", df["Age Group"].value_counts(), "\n")
print("Product Category:\n", df["Product Category"].value_counts(), "\n")
print("Purchase Method:\n", df["Purchase Method"].value_counts(), "\n")
print("Location (Top 10):\n", df["Location"].value_counts().head(10), "\n")

"""### Sales Trend Over Time"""

monthly_sales = df.set_index('Purchase Date')['Net Amount'].resample('M').sum().reset_index()

plt.figure(figsize=(14, 7))
sns.lineplot(x='Purchase Date', y='Net Amount', data=monthly_sales)
plt.title('Total Net Sales Over Time (Monthly)', fontsize=16)
plt.xlabel('Date', fontsize=12)
plt.ylabel('Total Net Sales (INR)', fontsize=12)
plt.grid(True)
plt.show()

"""### Purchase Method Distribution"""

method_counts = df['Purchase Method'].value_counts()
plt.figure(figsize=(10, 8))
plt.pie(method_counts, labels=method_counts.index, autopct='%1.1f%%', startangle=140,
        wedgeprops={'edgecolor': 'white'})
plt.title('Distribution of Purchase Methods', fontsize=16)
plt.axis('equal')
plt.legend(title='Payment Methods', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

"""### Sales by Location"""

location_sales = df.groupby('Location')['Net Amount'].sum().nlargest(10).reset_index()
plt.figure(figsize=(12, 7))
sns.barplot(x='Net Amount', y='Location', data=location_sales, palette='viridis')
plt.title('Top 10 Locations by Total Net Sales', fontsize=16)
plt.xlabel('Total Net Sales (INR)', fontsize=12)
plt.ylabel('Location', fontsize=12)
plt.show()

"""### Sales Product by category"""

category_sales = df.groupby("Product Category")["Net Amount"].sum().reset_index()
plt.figure(figsize=(10,6))
sns.barplot(x="Product Category", y="Net Amount", data=category_sales)
plt.xticks(rotation=90, ha="right")
plt.title("Total Sales by Product Category")
plt.ylabel("Total Net Sales (INR)")
plt.xlabel("Product Category")
plt.show()

"""### Sales by Gender"""

gender_sales = df.groupby("Gender")["Net Amount"].sum().reset_index()
plt.figure(figsize=(7,3))
sns.barplot(x="Gender", y="Net Amount", data=gender_sales)
plt.title("Total Sales by Gender")
plt.ylabel("Total Net Sales (INR)")
plt.show()

"""### Sales by Age"""

age_sales = df.groupby("Age Group")["Net Amount"].sum().reset_index()
plt.figure(figsize=(6,4))
sns.barplot(x="Age Group", y="Net Amount", data=age_sales)
plt.title("Total Sales by Age Group")
plt.ylabel("Total Net Sales (INR)")
plt.show()

"""### Sales by Product Category and location"""

top_locations = df["Location"].value_counts().head(10).index
df_top_locations = df[df["Location"].isin(top_locations)]

pivot_location_category = df_top_locations.pivot_table(
    values="Net Amount", index="Location", columns="Product Category", aggfunc="sum", fill_value=0
)
plt.figure(figsize=(12,6))
sns.heatmap(pivot_location_category, cmap="coolwarm", annot=False, cbar_kws={'label': 'Net Sales (INR)' })
plt.title("Sales by Product Category across Top 10 Locations")
plt.ylabel("Location")
plt.xlabel("Product Category")
plt.show()

"""# Business Questions:

1. Which Product Category generates the highest revenue by
sale?
2. Which age group and gender contribute to most of the sales in total?
3. How do the sales vary in different regions?
4. Which of purchase methods (Debit Card, Cash On Delivery, etc) is most common among the customer?
5. What is the fluctuation of sales for top product categories by season and time of day?
6. What relationship do Discount_Percentage and Purchase_Frequency show?

### Business Questions 1:


Which Product Category generates the highest revenue by sale?
"""

category_sales = df.groupby("Product Category")["Net Amount"].sum().reset_index().sort_values(by="Net Amount", ascending=False)
plt.figure(figsize=(10,6))
sns.barplot(x="Product Category", y="Net Amount", data=category_sales)
plt.xticks(rotation=45, ha="right")
plt.title("Q1: Sales Revenue by Product Category")
plt.ylabel("Total Net Sales (INR)")
plt.show()

"""Electronics is the highest revenue generator by a big margin. It is followed by Clothing and Beauty & Health with a steep decline in the remaining categories.

### Business Question 2:

Which age group and gender contribute to most of the sales in total?
"""

gender_age_sales = df.groupby(["Gender", "Age Group"])["Net Amount"].sum().reset_index()
plt.figure(figsize=(10,6))
sns.barplot(x="Age Group", y="Net Amount", hue="Gender", data=gender_age_sales)
plt.title("Q2: Sales by Age Group and Gender")
plt.ylabel("Total Net Sales (INR)")
plt.show()

"""* Females in the age group "25-45" contribute the most to sales, followed by "18-25" which a significant drop for "45-60" and less volumes for "under 18" and "60 and above".
* In each age group, all the three gender segments are close but the "Other" segment slightly towers over Female and Male.

### Business Question 3:

How do the sales vary in different regions?
"""

top_location_sales = df.groupby("Location")["Net Amount"].sum().reset_index().sort_values(by="Net Amount", ascending=False).head(10)
plt.figure(figsize=(10,6))
sns.barplot(x="Location", y="Net Amount" , data=top_location_sales)
plt.xticks(rotation=90, ha="right")
plt.title("Q3: Top 10 Locations by Sales")
plt.ylabel("Total Net Sales (INR)")
plt.show()

"""* Mumbai has the highest amount of sales followed by Delhi.
* Bangalore being third shows a noticable drop then a longer tail across the rest of the cities.
* The lower tier (Ahmedabad, Kolkata and Lucknow) show a substantially smaller sale which highlights a steeper concentration of revenue in high tier cities.

### Business Question 4:

 Which of purchase methods(Debit Card, Cash On Delivery, etc) is most common among the customer?
"""

method_sales = df["Purchase Method"].value_counts().reset_index()
method_sales.columns = ["Purchase Method", "Count"]
plt.figure(figsize=(8,5))
sns.barplot(x="Purchase Method", y="Count", data=method_sales)
plt.title("Q4: Most Common Purchase Methods")
plt.ylabel("Number of Transactions")
plt.xticks(rotation=45, ha="right")
plt.show()

"""* Credit Card has the highest bar by a margin, this indicates that it is the most preferred method of purschase by the customers.
* Debit cards come second with high usage too but below credit card. This reinforces that card based payments are the preferred method of payment.
* The distribution is highly skewed as only two methods account for most of the payments made while the others contribute very less.

### Business Question 5:
What is the fluctuation of sales for top product categories by season(5.1) and time of day(5.2)?
"""

# 5.1

df_top_categories = df[df['Product Category'].isin(['Electronics', 'Clothing'])]
seasonal_sales = df_top_categories.groupby(['Purchase_Season', 'Product Category'])['Net Amount'].sum().reset_index()
plt.figure(figsize=(10, 6))
sns.barplot(x='Purchase_Season', y='Net Amount', hue='Product Category', data=seasonal_sales,
            order=['Spring', 'Summer', 'Autumn', 'Winter'])
plt.title('Seasonal Sales Performance: Electronics vs. Clothing')
plt.xlabel('Season')
plt.ylabel('Total Net Sales (in millions INR)')
plt.ticklabel_format(style='plain', axis='y')
plt.legend(title='Product Category')
plt.show()

# 5.2

daily_sales = df_top_categories.groupby(['Purchase_TimeOfDay', 'Product Category'])['Net Amount'].sum().reset_index()
plt.figure(figsize=(10, 6))
sns.barplot(x='Purchase_TimeOfDay', y='Net Amount', hue='Product Category', data=daily_sales,
            order=['Morning', 'Afternoon', 'Evening', 'Night'])
plt.title('Sales Performance by Time of Day: Electronics vs. Clothing')
plt.xlabel('Time of Day')
plt.ylabel('Total Net Sales (in millions INR)')
plt.ticklabel_format(style='plain', axis='y')
plt.legend(title='Product Category')
plt.show()

"""5.1:
* From the visuals above, it is seen that Electronics consistently outsells Clothing across all seasons, having the largest margin in Autumn and the smallest in summer.
* Seasonal spikes are smaller for clothes as compared to Electronics. This suggests it has a steadier baseline demand.

5.2:
* Electronics outsell clothing at every time of the day.
* Both peak at night and bottom in the evening.

### Business Question 6
What products have the highest customer churn?
"""

churn_pivot = df.pivot_table(
    values='Is_Churned',
    index='Product Category',
    columns='Age Group',
    aggfunc='mean'
)

age_order = ['under 18', '18-25', '25-45', '45-60', '60 and above']
churn_pivot = churn_pivot[age_order]

plt.figure(figsize=(12, 8))
sns.heatmap(
    churn_pivot,
    annot=True,
    fmt='.1%',
    cmap='coolwarm'
)

plt.title('Customer Churn Rate by Product Category and Age Group', fontsize=16)
plt.xlabel('Age Group', fontsize=12)
plt.ylabel('Product Category', fontsize=12)
plt.show()

"""* The churn rates are high across all categories and ages.
* Highest churn is seen in Toys & Games for the 60 and above group at 87.5%.
* Clothing has a high churn rate for under 18 at 81.5%.
* Pet care shows contrasting pattern. It has a low churn for ages 45 - 60 at 74.1% while higher churn at 82.4% for 60 and above.
* Books show lower churn under 18 and moderate churn in others.
* Electronics show stable churn across ages depicting limited age driven variation.

##Conclusion

The Explanatory Data Analysis revealed that RovanMart's success depends on a few strong categories and a clear demographic base.

1. In this analysis of 55,000 transactions, revenue concentration was found at Electronics, followed by Clothing and Beauty & Health and a trail of low impact groups.

2. Revenue is centered towards Tier 1 cities with Mumbai and Delhi on top and steep decline in other cities.

3. Card Payments are popular, especially Credit Card.

4. Time and season features revealed strong Nighttime sales conversion performance and peak in Autumn.

## Final Discussion

* The analysis gives a clear structured narration of customer behavior and sales trends.
* Transaction data enabled us to explore various dimensions such as demographics, time, discounts and payment methods.
* The visualizations makes it easier to interpret the findings in a way that is easier for the non-technical business stakeholders to comprehend.
* Primary revenue drivers and customer segments were identified giving the company actionable focus sectors.
"""